{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from scipy.stats import pearsonr\n",
    "from scipy.stats import spearmanr\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from scipy import spatial\n",
    "from scipy import stats\n",
    "\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.autograd as autograd\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "torch.manual_seed(1)\n",
    "\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "from collections import defaultdict\n",
    "from collections import Counter\n",
    "\n",
    "from random import randint\n",
    "import pickle\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('error')\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from scipy import spatial\n",
    "\n",
    "import string\n",
    "puncs = set(string.punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class EmbedAlign(nn.Module):\n",
    "    def __init__(self, vocab_size_en,vocab_size_fr, embedding_dim):\n",
    "        super(EmbedAlign, self).__init__()\n",
    "        \n",
    "        self.vocab_size_en = vocab_size_en\n",
    "        self.vocab_size_fr = vocab_size_fr\n",
    "        self.embedding_dim = embedding_dim\n",
    "        #for the inference model\n",
    "        self.w_embeddings = nn.Embedding(self.vocab_size_en, self.embedding_dim)\n",
    "        #encoder        \n",
    "        self.bidirLSTM = nn.LSTM(self.embedding_dim, self.embedding_dim, bidirectional=True)\n",
    "        #h_i = hi< + hi>\n",
    "        \n",
    "        self.mu_1 = nn.Linear(self.embedding_dim, self.embedding_dim)\n",
    "        self.mu_2 = nn.Linear(self.embedding_dim, self.embedding_dim)\n",
    "            \n",
    "        self.sigma_1 = nn.Linear(self.embedding_dim, self.embedding_dim)\n",
    "        self.sigma_2 = nn.Linear(self.embedding_dim, self.embedding_dim)\n",
    "        \n",
    "        #for the generative model\n",
    "        self.affine1L1 = nn.Linear(self.embedding_dim, self.embedding_dim)\n",
    "        self.affine2L1 = nn.Linear(self.embedding_dim, self.vocab_size_en)\n",
    "        \n",
    "        self.affine1L2 = nn.Linear(self.embedding_dim, self.embedding_dim)\n",
    "        self.affine2L2 = nn.Linear(self.embedding_dim, self.vocab_size_fr)\n",
    "       \n",
    "        self.dist_norm = torch.distributions.multivariate_normal.MultivariateNormal(torch.ones(self.embedding_dim),torch.diag(torch.ones(self.embedding_dim)))\n",
    "            \n",
    "    def forward(self, batch_en, batch_fr, mu_i, sigma_i, z_i, best_alignments):\n",
    "        \n",
    "        kl_score = 0.0\n",
    "        sent_logx = 0.0\n",
    "        sent_logy = 0.0\n",
    "        \n",
    "        m = len(batch_en)\n",
    "        \n",
    "        for x in range(len(batch_en)):\n",
    "            \n",
    "            word_x = batch_en[x]\n",
    "            embeddings = self.w_embeddings(word_x)\n",
    "            #view_shape = embeddings.shape[0]\n",
    "            output, (hidden, cell) = self.bidirLSTM(embeddings.view(1, 1, -1)) \n",
    "\n",
    "            hid_f = hidden[0]\n",
    "            hid_b = hidden[1]\n",
    "\n",
    "            conc_hids = hid_f + hid_b\n",
    "            \n",
    "            mu = self.mu_1(conc_hids.squeeze())\n",
    "            mu = F.relu(mu)\n",
    "            mu = self.mu_2(mu)\n",
    "\n",
    "            sigma = self.sigma_1(conc_hids.squeeze())\n",
    "            sigma = F.relu(sigma)\n",
    "            sigma = self.sigma_2(sigma)\n",
    "            sigma = F.softplus(sigma)\n",
    "\n",
    "            mu_i.append((word_x, mu))\n",
    "            sigma_i.append((word_x,sigma))\n",
    "            \n",
    "            epsilon = torch.distributions.multivariate_normal.MultivariateNormal(torch.zeros(self.embedding_dim),torch.diag(torch.ones(self.embedding_dim))).sample()\n",
    "\n",
    "            #reparameterize\n",
    "            zi = mu + epsilon * sigma\n",
    "            z_i.append((word_x, zi))\n",
    "            \n",
    "            #generative using sampled zi\n",
    "            #variational location and scale\n",
    "            #same zi for x and y\n",
    "\n",
    "            xi = self.affine1L1(zi)\n",
    "            xi = F.relu(xi)\n",
    "            xi = self.affine2L1(xi)\n",
    "            xi = F.log_softmax(xi, dim=0) #cat generation - target\n",
    "\n",
    "            yi = self.affine1L2(zi)\n",
    "            yi = F.relu(yi)\n",
    "            yi = self.affine2L2(yi)\n",
    "            yi = F.log_softmax(yi, dim=0) #cat generation - source\n",
    "\n",
    "            sent_logx += xi[word_x]\n",
    "            \n",
    "            #mu[torch.isnan(mu)] = 0\n",
    "            #print(mu_i[x], sigma_i[x])\n",
    "            \n",
    "            kl_loss = -(1 + torch.log(sigma**2) - mu ** 2 - sigma**2)/2\n",
    "            \n",
    "            kl_score += kl_loss\n",
    "            \n",
    "            best_j = 0\n",
    "            best_prob = 0\n",
    "            for y in range(len(batch_fr)):\n",
    "                word_y = batch_fr[y]\n",
    "                y_prob = yi[word_y].data\n",
    "                exp_y_prob = np.exp(y_prob)\n",
    "                \n",
    "                if exp_y_prob > best_prob:\n",
    "                    best_prob = exp_y_prob\n",
    "                    best_j = y \n",
    "                    best_y_prob = y_prob\n",
    "                    \n",
    "            best_alignments.append((x,best_j))\n",
    "                    \n",
    "            sent_logy += (-torch.Tensor([np.log(m)])) + best_y_prob\n",
    "                \n",
    "        final_out = -sent_logx - sent_logy + torch.sum(kl_score)\n",
    "            \n",
    "        return final_out, mu_i, sigma_i, xi,yi,z_i, best_alignments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('mu_0.pickle', 'rb') as f:\n",
    "    mu = pickle.load(f)\n",
    "    \n",
    "with open('sigma_0.pickle', 'rb') as f:\n",
    "    sigma = pickle.load(f)\n",
    "    \n",
    "with open('xi_0.pickle', 'rb') as f:\n",
    "    xi = pickle.load(f)\n",
    "    \n",
    "with open('yi_0.pickle', 'rb') as f:\n",
    "    yi = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "portion = 1000\n",
    "\n",
    "with open('model_embed' + str(portion) + '.pickle', 'rb') as f:\n",
    "     model = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('tokens2id_hansard_en_subs.pickle', 'rb') as f:\n",
    "    tokens2id_en = pickle.load(f)\n",
    "    \n",
    "with open('tokens2id_hansard_fr_subs.pickle', 'rb') as f:\n",
    "    tokens2id_fr = pickle.load(f)\n",
    "    \n",
    "with open('id2tokens_hansard_en_subs.pickle', 'rb') as f:\n",
    "    id2tokens_en = pickle.load(f)\n",
    "    \n",
    "with open('id2tokens_hansard_fr_subs.pickle', 'rb') as f:\n",
    "    id2tokens_fr = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7199"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(yi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('lst/lst.gold.candidates') as file:\n",
    "    whole_gold = file.read().splitlines() \n",
    "    \n",
    "    gold_cands_l = [l.split('::') for l in whole_gold]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gold_cands = defaultdict(dict)\n",
    "\n",
    "for g in gold_cands_l:\n",
    "    word_pos = g[0]\n",
    "    \n",
    "    word, postag = word_pos.split('.')\n",
    "    \n",
    "    candidates = g[1].split(';')\n",
    "    \n",
    "    gold_cands[word] = {'postag':postag, 'candidates':candidates}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('lst/lst_test.preprocessed') as file:\n",
    "    \n",
    "    lst_sentences = [l.split() for l in file.readlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lst_test_preprocessed = defaultdict(dict)\n",
    "\n",
    "for l in lst_sentences:\n",
    "    word, postag = l[0].split('.')\n",
    "    sentence_no = int(l[1])\n",
    "    word_position = int(l[2])\n",
    "    sentence_tokens = l[3:]\n",
    "    \n",
    "    processed_tokens = []\n",
    "    \n",
    "    #remove punctuations TODO position might change\n",
    "    punc_inds = []\n",
    "    for s in range(len(sentence_tokens)):\n",
    "        \n",
    "        if sentence_tokens[s] not in puncs:\n",
    "            processed_tokens.append(sentence_tokens[s])\n",
    "        else:\n",
    "            punc_inds.append(s)\n",
    "                \n",
    "    temp_word_position = word_position\n",
    "    \n",
    "    for d in punc_inds:\n",
    "        if d < temp_word_position:\n",
    "            word_position -= 1\n",
    "        \n",
    "    lst_test_preprocessed[(word,sentence_no)] = {'postag':postag, 'word_position':word_position,'sentence':processed_tokens}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_context_window(sentence, central_word_index, window_size):\n",
    "    \n",
    "    context = []\n",
    "    word = sentence[central_word_index]\n",
    "    \n",
    "    for w in range(1,window_size+1):\n",
    "        \n",
    "        left_cont = central_word_index - w\n",
    "        right_cont = central_word_index + w\n",
    "        \n",
    "        #find the window words to the left and right\n",
    "        #add as pair if they are inside sentence boundaries\n",
    "        \n",
    "        if left_cont > -1:\n",
    "            context.append(sentence[left_cont])\n",
    "            \n",
    "        if right_cont < len(sentence):\n",
    "            context.append(sentence[right_cont])\n",
    "            \n",
    "    return context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def out_ranked_results(word, postag, sentence_id, sorted_d):\n",
    "    \n",
    "    word_pos = str(word+'.'+postag)\n",
    "    res = 'RANKED\\t' + word_pos + ' '+ str(sentence_id)\n",
    "    \n",
    "    for d in sorted_d:\n",
    "        res += '\\t' + d[0]+' '+ str(d[1])\n",
    "    \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1709\n"
     ]
    }
   ],
   "source": [
    "results_to_write_cos = []\n",
    "results_to_write_KL = []\n",
    "\n",
    "len_w_embeds = 6330\n",
    "embedding_dim = 100\n",
    "\n",
    "for ls in lst_test_preprocessed:\n",
    "\n",
    "    #GET WORD AND SENTENCE RELATED INFO\n",
    "    item = lst_test_preprocessed[ls]\n",
    "    central_word = ls[0]\n",
    "    sentence_id = ls[1]\n",
    "\n",
    "    postag = item['postag']\n",
    "    word_position = item['word_position']\n",
    "    sentence = item['sentence']\n",
    "    \n",
    "    sentence = torch.tensor(sentence2id(sentence, tokens2id_en), dtype = torch.long)\n",
    "    \n",
    "    sent_f = sentence #dummy\n",
    "\n",
    "    #get the list of candidate gold annotations\n",
    "    cands = gold_cands[central_word]['candidates']\n",
    "    \n",
    "    z_i = []\n",
    "    mu_i = []\n",
    "    sigma_i = []\n",
    "    best_alignments = []\n",
    "    \n",
    "\n",
    "    loss, mu_i, sigma_i, xi,yi,z_i, best_alignments = model(sentence, sent_f,mu_i, sigma_i, z_i, best_alignments)\n",
    "\n",
    "    cos_sims = defaultdict(float)\n",
    "    KL_scores = defaultdict(float)\n",
    "  \n",
    "    if central_word in tokens2id_en:\n",
    "        id_token = tokens2id_en[central_word]\n",
    "\n",
    "        if id_token < len_w_embeds:\n",
    "            #get the parameters of the word\n",
    "            embed1_mu = mu_i[word_position][1]\n",
    "            embed1_sigma = sigma_i[word_position][1]\n",
    "\n",
    "            #just mean at test time - confirmed with Miguel\n",
    "            z_central = (embed1_mu).detach().numpy()\n",
    "                        \n",
    "            z_central = z_central/np.linalg.norm(z_central.data)\n",
    "\n",
    "            for c in cands:\n",
    "                #for each candidate find the cosine similarity between target and central\n",
    "\n",
    "                if c in tokens2id_en:\n",
    "                    id_for_cand = tokens2id_en[c]\n",
    "\n",
    "                    if id_for_cand < len_w_embeds:\n",
    "\n",
    "                        #sentences with the candidate word\n",
    "                        sentence[word_position] = id_for_cand\n",
    "                        loss, mu_i, sigma_i, xi,yi,z_i, best_alignments = model(sentence, sent_f,mu_i, sigma_i, z_i, best_alignments)\n",
    "\n",
    "                        #get the parameters of the word\n",
    "                        embed2_mu = mu_i[word_position][1]\n",
    "                        embed2_sigma = sigma_i[word_position][1]\n",
    "\n",
    "                        #just mean at test time - confirmed with Miguel\n",
    "                        z_context = (embed2_mu).detach().numpy()\n",
    "                        z_context = z_context / np.linalg.norm(z_context.data)\n",
    "\n",
    "                        cosine_similarity = 1 - spatial.distance.cosine(z_central, z_context)\n",
    "                        cos_sims[c] = cosine_similarity\n",
    "\n",
    "                        loss1 = torch.log(embed1_sigma/embed2_sigma) \n",
    "                        numerator = (embed2_sigma.pow(2) + (embed1_mu - embed1_sigma).pow(2))\n",
    "                        KL_scores[c] = (loss1 + numerator / (2*embed1_sigma.pow(2)) - 0.5).sum()\n",
    "                        KL_scores[c] = KL_scores[c].data.numpy()\n",
    "                else:\n",
    "                    cos_sims[c] = 0\n",
    "                    KL_scores[c] = float('inf')\n",
    "                \n",
    "        sorted_d_cos = sorted(cos_sims.items(), key=lambda x: x[1], reverse=True)\n",
    "        sorted_d_KL = sorted(KL_scores.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "        ranked_res_cos = out_ranked_results(central_word, postag, sentence_id, sorted_d_cos)\n",
    "        ranked_res_kl = out_ranked_results(central_word, postag, sentence_id, sorted_d_KL)\n",
    "\n",
    "        results_to_write_cos.append(ranked_res_cos)\n",
    "        results_to_write_KL.append(ranked_res_kl)\n",
    "    else:\n",
    "\n",
    "        for c in cands:\n",
    "\n",
    "            id_for_cand = tokens2id_en[c]\n",
    "\n",
    "            cos_sims[c] = 0\n",
    "\n",
    "            KL_scores[c] = float('inf')\n",
    "            \n",
    "        sorted_d_cos = sorted(cos_sims.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "        sorted_d_KL = sorted(KL_scores.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "        ranked_res_cos = out_ranked_results(central_word, postag, sentence_id, sorted_d_cos)\n",
    "        \n",
    "        ranked_res_kl = out_ranked_results(central_word, postag, sentence_id, sorted_d_KL)\n",
    "\n",
    "        results_to_write_cos.append(ranked_res_cos)\n",
    "        results_to_write_KL.append(ranked_res_kl)\n",
    "\n",
    "        \n",
    "file_name = 'embedalign_lst_cos.txt'\n",
    "\n",
    "results_to_write = results_to_write_cos\n",
    "with open (file_name, 'w') as f:\n",
    "\n",
    "    for r in range(len(results_to_write)):\n",
    "\n",
    "        if r == len(results_to_write) - 1:\n",
    "            print(r)\n",
    "            f.write(results_to_write[r])\n",
    "        else:\n",
    "            f.write(results_to_write[r])\n",
    "            f.write('\\n')\n",
    "            \n",
    "file_name = 'embedalign_lst_kl.txt'\n",
    "\n",
    "results_to_write = results_to_write_KL\n",
    "\n",
    "\n",
    "with open (file_name, 'w') as f:\n",
    "\n",
    "    for r in range(len(results_to_write)):\n",
    "\n",
    "        if r == len(results_to_write) - 1:\n",
    "            f.write(results_to_write[r])\n",
    "        else:\n",
    "            f.write(results_to_write[r])\n",
    "            f.write('\\n')\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ece/Desktop/ulllab/ULL-lab/Untitled Folder/ULL-labs/ULL-2\n"
     ]
    }
   ],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ece/Desktop/ulllab/ULL-lab/Untitled Folder/ULL-labs/ULL-2/lst\n"
     ]
    }
   ],
   "source": [
    "cd lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MEAN_GAP\t0.267197711765367\n",
      "\n",
      "\n",
      "MEAN_GAP\t0.29614730845081483\n",
      "\n"
     ]
    }
   ],
   "source": [
    "! python lst_gap.py lst_test.gold embedalign_lst_kl.txt out no-mwe\n",
    "! python lst_gap.py lst_test.gold embedalign_lst_cos.txt out no-mwe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "447\n"
     ]
    }
   ],
   "source": [
    "test_e = 'testing/test/test.e'\n",
    "test_f = 'testing/test/test.f'\n",
    "\n",
    "with open(test_e) as e:\n",
    "    test_sentences_e = [l.split() for l in e.readlines()]\n",
    "with open(test_f) as f:\n",
    "    test_sentences_f = [l.split() for l in f.readlines()]\n",
    "\n",
    "num_test_sentences = len(test_sentences_e)\n",
    "print(num_test_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37\n"
     ]
    }
   ],
   "source": [
    "dev_e = 'validation/dev.e'\n",
    "dev_f = 'validation/dev.f'\n",
    "\n",
    "with open(dev_e) as e:\n",
    "    val_sentences_e = [l.split() for l in e.readlines()]\n",
    "with open(dev_e) as f:\n",
    "    val_sentences_f = [l.split() for l in f.readlines()]\n",
    "\n",
    "num_val_sentences = len(val_sentences_e)\n",
    "print(num_val_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#convert sentence tokens to ids\n",
    "def sentence2id(sentence, tokens2id_lang):\n",
    "    \n",
    "    s_ids = []\n",
    "    \n",
    "    for w in sentence:\n",
    "        \n",
    "        token_id = tokens2id_lang[w.lower()]\n",
    "\n",
    "        s_ids.append(token_id)\n",
    "        \n",
    "    return s_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#alignment\n",
    "\n",
    "def write_test_results(filename, model, sentences_e, sentences_f):\n",
    "    \n",
    "    with open(filename,\"w\") as naaclfile:\n",
    "        \n",
    "        for sent in range(len(sentences_e)):\n",
    "            \n",
    "            z_i = []\n",
    "            mu_i = []\n",
    "            sigma_i = []\n",
    "            \n",
    "            sent_e = sentences_e[sent]\n",
    "            sent_f = sentences_f[sent]\n",
    "\n",
    "            l = len(sent_e) #includes null\n",
    "            m = len(sent_f)\n",
    "\n",
    "            sent_e = torch.tensor(sentence2id(sent_e, tokens2id_en), dtype=torch.long)\n",
    "            sent_f = torch.tensor(sentence2id(sent_f, tokens2id_fr), dtype=torch.long)\n",
    "            \n",
    "            best_alignments = []\n",
    "            \n",
    "            loss, mu_i, sigma_i, xi,yi,z_i, best_alignments = model(sent_e, sent_f,mu_i, sigma_i, z_i, best_alignments)\n",
    "\n",
    "            for b_pair in best_alignments:\n",
    "             \n",
    "                naaclfile.write(str(sent+1) + \" \" + str(b_pair[0]+1) + \" \" + str(b_pair[1]+1) + \" S\" + \"\\n\")                \n",
    "\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('model_embed.pickle', 'rb') as f:\n",
    "    model = pickle.load(f)\n",
    "    \n",
    "write_test_results('naacl_embed_test', model,test_sentences_e, test_sentences_f)\n",
    "\n",
    "write_test_results('naacl_embed_val', model,val_sentences_e, val_sentences_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
