{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from scipy.stats import pearsonr\n",
    "from scipy.stats import spearmanr\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from scipy import spatial\n",
    "from scipy import stats\n",
    "\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.autograd as autograd\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "torch.manual_seed(1)\n",
    "\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "from collections import defaultdict\n",
    "from collections import Counter\n",
    "\n",
    "from random import randint\n",
    "import pickle\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "# import warnings\n",
    "# warnings.filterwarnings('error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "embedding_dim = 100\n",
    "learning_rate = 0.025\n",
    "epochs = 10\n",
    "batch_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "label='_hansard_en_smaller'\n",
    "\n",
    "with open('pos_data' + label +'.p', 'rb') as f:\n",
    "    pos_data = pickle.load(f)\n",
    "    \n",
    "with open('neg_data' + label +'.p', 'rb') as f:\n",
    "    neg_data = pickle.load(f)\n",
    "\n",
    "with open('unigram_probs' + label +'.p', 'rb') as f:\n",
    "    unigram_probs = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "706104"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pos_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# portion = len(all_pos_data)\n",
    "# #portion = 100\n",
    "# pos_data = all_pos_data[:portion]\n",
    "# neg_data = all_neg_data[:portion]\n",
    "#unigram_probs = all_unigram_probs\n",
    "\n",
    "vocab_size = len(unigram_probs)\n",
    "\n",
    "central_words = []\n",
    "contexts = []\n",
    "neg_samples = []\n",
    "\n",
    "for p in pos_data:\n",
    "    central_words.append(p[0])\n",
    "    contexts.append(p[1])\n",
    "    \n",
    "for n in neg_data:\n",
    "    neg_samples.append(n[1])\n",
    "    \n",
    "dataset = [central_words, contexts, neg_samples]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2949\n",
      "706104\n"
     ]
    }
   ],
   "source": [
    "print(vocab_size)\n",
    "print(len(dataset[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[     0      1      2 ..., 706101 706102 706103]\n"
     ]
    }
   ],
   "source": [
    "def create_batches(dataset, batch_size):\n",
    "    \n",
    "    batch_number = len(dataset[0]) // batch_size\n",
    "    no_central_words = len(dataset[0])\n",
    "    pos_words = []\n",
    "    pos_contexts = []\n",
    "    neg_contexts = []\n",
    "    \n",
    "\n",
    "    indices = np.arange(0, no_central_words)\n",
    "    print(indices)\n",
    "    #shuffle set\n",
    "    np.random.shuffle(indices)\n",
    "    \n",
    "    for bn in range(batch_number):\n",
    "        \n",
    "        b_indices = indices[bn*batch_size:bn*batch_size + batch_size]\n",
    "        \n",
    "        central = []\n",
    "        contx = []\n",
    "        negs = []\n",
    "        \n",
    "        for d in b_indices:\n",
    "            central.append(dataset[0][d])\n",
    "            contx.append(dataset[1][d])\n",
    "            negs.append(dataset[2][d])\n",
    "              \n",
    "        pos_words.append(torch.from_numpy(np.asarray(central)))\n",
    "        pos_contexts.append(torch.from_numpy(np.asarray(contx)))\n",
    "        neg_contexts.append(torch.from_numpy(np.asarray(negs)))\n",
    "    \n",
    "    return  pos_words, pos_contexts, neg_contexts\n",
    "\n",
    "pos_words, pos_contexts, neg_contexts = create_batches(dataset, batch_size)\n",
    "\n",
    "batched_dataset = {'pos_w': pos_words, 'pos_c': pos_contexts, 'neg_c':neg_contexts}\n",
    "\n",
    "with open('batched_dataset' +label+'.p', 'wb') as f:\n",
    "    pickle.dump(batched_dataset, f) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('batched_dataset' +label+'.p', 'rb') as f:\n",
    "    batched_dataset = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  282,  2298,  1721,   690,  2026,  1256,  1951,  1721,  2588,\n",
       "         1231,  1023,  2285,  2905,  2148,   293,  1966,  2133,  1461,\n",
       "         2113,  1612,  1074,  2839,  1177,  1721,  2610,  1074,   445,\n",
       "         1793,   374,  1612,   668,  2404,   123,  1945,  1721,  2762,\n",
       "          164,  1388,  1378,  2070,  1721,  2384,   123,  2545,  2214,\n",
       "         2715,   734,  2517,  1394,  2436,  1914,   587,  2755,  2880,\n",
       "         1445,  1284,   577,  2880,  1074,  1074,  1088,  1372,  1605,\n",
       "         1628,  2727,   773,  1266,   827,  2270,  1074,   856,  1100,\n",
       "         2880,  2398,   235,  1074,  2136,  1865,  1100,    32,  2148,\n",
       "         1074,  2081,  1388,  1481,  1074,  1938,    15,  1134,  2472,\n",
       "         1344,   123,  2119,  1234,  1033,   492,  1899,   308,   123,\n",
       "         2006])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batched_dataset['pos_w'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7061"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(batched_dataset['pos_c'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word_batches = batched_dataset['pos_w']\n",
    "context_batches = batched_dataset['pos_c']\n",
    "neg_context_batches = batched_dataset['neg_c']\n",
    "\n",
    "no_batch = len(word_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# class SkipGram(nn.Module):\n",
    "#     def __init__(self, vocabulary_size, embedding_dim):\n",
    "#         super(SkipGram, self).__init__()\n",
    "        \n",
    "#         #sparse embeddings for word and context vectors\n",
    "#         self.w_embeddings = nn.Embedding(vocabulary_size, embedding_dim) #, sparse = True\n",
    "#         self.lin1 = nn.Linear(embedding_dim, vocabulary_size, bias = False)\n",
    "           \n",
    "#     def forward(self, pos_words):\n",
    "        \n",
    "#         out = self.w_embeddings(pos_words)\n",
    "        \n",
    "#         out = self.lin1(out)\n",
    "        \n",
    "#         final_out = F.log_softmax(out, dim = 0)\n",
    "        \n",
    "#         return final_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# model = SkipGram(vocab_size, embedding_dim)\n",
    "# loss_func = nn.NLLLoss()\n",
    "# optimizer = optim.Adam(model.parameters(), lr = learning_rate)\n",
    "\n",
    "# for e in range(epochs):\n",
    "    \n",
    "#     print(e)\n",
    "#     total_loss = 0.0\n",
    "#     for b in range(no_batch):\n",
    "        \n",
    "#         words = word_batches[b]\n",
    "        \n",
    "#         contexts = context_batches[b]\n",
    "\n",
    "#         optimizer.zero_grad()\n",
    "\n",
    "#         preds = model(words)\n",
    "        \n",
    "#         loss = loss_func(preds, contexts)\n",
    "        \n",
    "#         loss.backward()\n",
    "        \n",
    "#         optimizer.step()\n",
    "\n",
    "#         total_loss += loss.item()\n",
    "        \n",
    "#     print(total_loss)\n",
    "    \n",
    "\n",
    "\n",
    "# with open('skipgram.pickle', 'wb') as file:\n",
    "#     pickle.dump(model,file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# with open('skipgram.pickle', 'rb') as file:\n",
    "#     model = pickle.load(file)\n",
    "\n",
    "# model.w_embeddings.weight[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class SkipGramNeg(nn.Module):\n",
    "    def __init__(self, vocabulary_size, embedding_dim):\n",
    "        super(SkipGramNeg, self).__init__()\n",
    "        \n",
    "        #sparse embeddings for word and context vectors\n",
    "        \n",
    "        self.w_embeddings = nn.Embedding(vocabulary_size, embedding_dim, sparse = True)\n",
    "        self.c_embeddings = nn.Embedding(vocabulary_size, embedding_dim, sparse = True)\n",
    "        \n",
    "        # initialization of embeds\n",
    "        # https://adoni.github.io/2017/11/08/word2vec-pytorch/\n",
    "\n",
    "#         initrange = 0.5 / embedding_dim\n",
    "#         self.w_embeddings.weight.data.uniform_(-initrange, initrange)\n",
    "#         self.c_embeddings.weight.data.uniform_(-0, 0)\n",
    "\n",
    "    def forward(self, pos_words, pos_conts, neg_conts):\n",
    "        \n",
    "        #Loss calculation, Levy&Goldberg word2vec Explained\n",
    "        #https://adoni.github.io/2017/11/08/word2vec-pytorch/\n",
    "        \n",
    "        w_out = self.w_embeddings(pos_words)\n",
    "        \n",
    "        pos_out = self.c_embeddings(pos_conts)\n",
    "        neg_out = self.c_embeddings(neg_conts)\n",
    "        \n",
    "#         print(neg_conts)\n",
    "#         print(pos_conts)\n",
    "#         print(pos_words)\n",
    "               \n",
    "        pos_val = torch.mul(w_out, pos_out).squeeze()\n",
    "        pos_val = torch.sum(pos_val, dim = 1)\n",
    "        pos_loss = F.logsigmoid(pos_val)\n",
    "        \n",
    "        neg_val = torch.bmm(neg_out, w_out.unsqueeze(2)).squeeze()\n",
    "        neg_val = torch.sum(neg_val, dim = 1)\n",
    "        neg_loss = F.logsigmoid(-neg_val)\n",
    "        \n",
    "        final_out = pos_loss + neg_loss.sum()\n",
    "        final_out = -final_out.sum()/len(pos_words) #neg and mean\n",
    "         \n",
    "        return final_out\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7061"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "no_batch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch, total loss, average loss, duration\n",
      "0 398345.07861828804 56.4148248999 0:00:24.767683\n",
      "1 45338.60941004753 31.4179073806 0:00:22.780337\n",
      "2 47382.88459920883 23.1821070022 0:00:23.644203\n",
      "3 49266.98877906799 19.1309149344 0:00:24.082728\n",
      "4 51093.57554626465 16.7519370331 0:00:24.146048\n",
      "5 51575.58900022507 15.1773291307 0:00:25.584251\n",
      "6 52627.02014064789 14.0738816051 0:00:25.554508\n",
      "7 53133.98136687279 13.255270632 0:00:24.323135\n",
      "8 52873.392003297806 12.6144726032 0:00:24.411276\n",
      "9 52734.06341671944 12.099860967 0:00:23.790315\n"
     ]
    }
   ],
   "source": [
    "model = SkipGramNeg(vocab_size, embedding_dim)\n",
    "optimizer = optim.SparseAdam(model.parameters(), lr = learning_rate)\n",
    "\n",
    "losses = []\n",
    "avg_losses = []\n",
    "\n",
    "print('epoch, total loss, average loss, duration')\n",
    "for e in range(epochs):\n",
    "    \n",
    "    then = datetime.now()\n",
    "    \n",
    "    total_loss = 0.0\n",
    "    for b in range(no_batch):\n",
    "        \n",
    "        words = word_batches[b]\n",
    "        contexts = context_batches[b]\n",
    "        neg_contexts = neg_context_batches[b]\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        loss = model(words, contexts, neg_contexts)\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()  \n",
    "    \n",
    "    now = datetime.now()\n",
    "        \n",
    "    losses.append(total_loss)\n",
    "    \n",
    "    avg_loss = np.mean(losses)/no_batch\n",
    "    \n",
    "    print(e, total_loss, avg_loss, now-then)\n",
    "    \n",
    "    avg_losses.append(avg_loss)\n",
    "    \n",
    "    wm, cm = get_embeddings(model)\n",
    "\n",
    "    save_embeddings(wm, 'wordvecs_skipgram_word_git.pickle')\n",
    "\n",
    "    save_embeddings(cm, 'wordvecs_skipgram_context_git.pickle')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_embeddings(model):\n",
    "    \n",
    "    return model.w_embeddings.weight.data, model.c_embeddings.weight.data\n",
    "\n",
    "def save_embeddings(embeds, file_name):\n",
    "    \n",
    "    with open(file_name, 'wb') as file:\n",
    "        pickle.dump(embeds.numpy(), file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f89d25bc470>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "iteration= list(range(len(avg_losses)))\n",
    "\n",
    "plt.plot(iteration, avg_losses)\n",
    "plt.xlabel(\"Iterations for Skipgram\")\n",
    "plt.ylabel('Average loss')\n",
    "plt.title('Evolution of average loss as a function of the iteration')\n",
    "plt.savefig(\"Skipgram.png\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "612"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(avg_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
