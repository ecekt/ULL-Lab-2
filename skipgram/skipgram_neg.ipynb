{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from scipy.stats import pearsonr\n",
    "from scipy.stats import spearmanr\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from scipy import spatial\n",
    "from scipy import stats\n",
    "\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.autograd as autograd\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "torch.manual_seed(1)\n",
    "\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "from collections import defaultdict\n",
    "from collections import Counter\n",
    "\n",
    "from random import randint\n",
    "import pickle\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "# import warnings\n",
    "# warnings.filterwarnings('error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "embedding_dim = 100\n",
    "learning_rate = 0.025\n",
    "epochs = 10\n",
    "batch_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "label='_hansard_en_smaller'\n",
    "\n",
    "with open('pos_data' + label +'.p', 'rb') as f:\n",
    "    pos_data = pickle.load(f)\n",
    "    \n",
    "with open('neg_data' + label +'.p', 'rb') as f:\n",
    "    neg_data = pickle.load(f)\n",
    "\n",
    "with open('unigram_probs' + label +'.p', 'rb') as f:\n",
    "    unigram_probs = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "706104"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pos_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# portion = len(all_pos_data)\n",
    "# #portion = 100\n",
    "# pos_data = all_pos_data[:portion]\n",
    "# neg_data = all_neg_data[:portion]\n",
    "#unigram_probs = all_unigram_probs\n",
    "\n",
    "vocab_size = len(unigram_probs)\n",
    "\n",
    "central_words = []\n",
    "contexts = []\n",
    "neg_samples = []\n",
    "\n",
    "for p in pos_data:\n",
    "    central_words.append(p[0])\n",
    "    contexts.append(p[1])\n",
    "    \n",
    "for n in neg_data:\n",
    "    neg_samples.append(n[1])\n",
    "    \n",
    "dataset = [central_words, contexts, neg_samples]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2949\n",
      "706104\n"
     ]
    }
   ],
   "source": [
    "print(vocab_size)\n",
    "print(len(dataset[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[     0      1      2 ..., 706101 706102 706103]\n"
     ]
    }
   ],
   "source": [
    "def create_batches(dataset, batch_size):\n",
    "    \n",
    "    batch_number = len(dataset[0]) // batch_size\n",
    "    no_central_words = len(dataset[0])\n",
    "    pos_words = []\n",
    "    pos_contexts = []\n",
    "    neg_contexts = []\n",
    "    \n",
    "\n",
    "    indices = np.arange(0, no_central_words)\n",
    "    print(indices)\n",
    "    #shuffle set\n",
    "    np.random.shuffle(indices)\n",
    "    \n",
    "    for bn in range(batch_number):\n",
    "        \n",
    "        b_indices = indices[bn*batch_size:bn*batch_size + batch_size]\n",
    "        \n",
    "        central = []\n",
    "        contx = []\n",
    "        negs = []\n",
    "        \n",
    "        for d in b_indices:\n",
    "            central.append(dataset[0][d])\n",
    "            contx.append(dataset[1][d])\n",
    "            negs.append(dataset[2][d])\n",
    "              \n",
    "        pos_words.append(torch.from_numpy(np.asarray(central)))\n",
    "        pos_contexts.append(torch.from_numpy(np.asarray(contx)))\n",
    "        neg_contexts.append(torch.from_numpy(np.asarray(negs)))\n",
    "    \n",
    "    return  pos_words, pos_contexts, neg_contexts\n",
    "\n",
    "pos_words, pos_contexts, neg_contexts = create_batches(dataset, batch_size)\n",
    "\n",
    "batched_dataset = {'pos_w': pos_words, 'pos_c': pos_contexts, 'neg_c':neg_contexts}\n",
    "\n",
    "with open('batched_dataset' +label+'.p', 'wb') as f:\n",
    "    pickle.dump(batched_dataset, f) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('batched_dataset' +label+'.p', 'rb') as f:\n",
    "    batched_dataset = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 2113,  2764,   577,  2008,  1074,   123,  1612,   517,  1074,\n",
       "         1256,  2567,   863,  1074,  2880,  1605,   731,   773,   921,\n",
       "         1721,  1074,  2116,  1234,  2880,  1851,  1074,  2763,  1721,\n",
       "         1074,  2317,  1678,  2364,  2301,  1461,  1234,  1074,   986,\n",
       "         1509,  1651,   123,  2904,  2763,  1100,   442,  2152,  2784,\n",
       "         1678,  2763,  1859,  1721,  1231,  2817,  1612,  2113,  1621,\n",
       "          370,  1721,  1721,   167,  1024,  1062,   176,  1020,  2782,\n",
       "          123,  1074,   256,  1651,  1914,  2880,  1914,  1074,  2552,\n",
       "         2880,  2880,  2099,  1234,  1719,  1828,   577,     0,  1373,\n",
       "         2041,   352,  1245,  1249,  2198,  1074,  1605,  1074,   123,\n",
       "          374,  1461,  2880,  2880,  1074,   492,  1074,  2017,   507,\n",
       "         2113])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batched_dataset['pos_w'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7061"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(batched_dataset['pos_c'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word_batches = batched_dataset['pos_w']\n",
    "context_batches = batched_dataset['pos_c']\n",
    "neg_context_batches = batched_dataset['neg_c']\n",
    "\n",
    "no_batch = len(word_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# class SkipGram(nn.Module):\n",
    "#     def __init__(self, vocabulary_size, embedding_dim):\n",
    "#         super(SkipGram, self).__init__()\n",
    "        \n",
    "#         #sparse embeddings for word and context vectors\n",
    "#         self.w_embeddings = nn.Embedding(vocabulary_size, embedding_dim) #, sparse = True\n",
    "#         self.lin1 = nn.Linear(embedding_dim, vocabulary_size, bias = False)\n",
    "           \n",
    "#     def forward(self, pos_words):\n",
    "        \n",
    "#         out = self.w_embeddings(pos_words)\n",
    "        \n",
    "#         out = self.lin1(out)\n",
    "        \n",
    "#         final_out = F.log_softmax(out, dim = 0)\n",
    "        \n",
    "#         return final_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# model = SkipGram(vocab_size, embedding_dim)\n",
    "# loss_func = nn.NLLLoss()\n",
    "# optimizer = optim.Adam(model.parameters(), lr = learning_rate)\n",
    "\n",
    "# for e in range(epochs):\n",
    "    \n",
    "#     print(e)\n",
    "#     total_loss = 0.0\n",
    "#     for b in range(no_batch):\n",
    "        \n",
    "#         words = word_batches[b]\n",
    "        \n",
    "#         contexts = context_batches[b]\n",
    "\n",
    "#         optimizer.zero_grad()\n",
    "\n",
    "#         preds = model(words)\n",
    "        \n",
    "#         loss = loss_func(preds, contexts)\n",
    "        \n",
    "#         loss.backward()\n",
    "        \n",
    "#         optimizer.step()\n",
    "\n",
    "#         total_loss += loss.item()\n",
    "        \n",
    "#     print(total_loss)\n",
    "    \n",
    "\n",
    "\n",
    "# with open('skipgram.pickle', 'wb') as file:\n",
    "#     pickle.dump(model,file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# with open('skipgram.pickle', 'rb') as file:\n",
    "#     model = pickle.load(file)\n",
    "\n",
    "# model.w_embeddings.weight[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class SkipGramNeg(nn.Module):\n",
    "    def __init__(self, vocabulary_size, embedding_dim):\n",
    "        super(SkipGramNeg, self).__init__()\n",
    "        \n",
    "        #sparse embeddings for word and context vectors\n",
    "        \n",
    "        self.w_embeddings = nn.Embedding(vocabulary_size, embedding_dim, sparse = True)\n",
    "        self.c_embeddings = nn.Embedding(vocabulary_size, embedding_dim, sparse = True)\n",
    "        \n",
    "        # initialization of embeds\n",
    "        # https://adoni.github.io/2017/11/08/word2vec-pytorch/\n",
    "\n",
    "#         initrange = 0.5 / embedding_dim\n",
    "#         self.w_embeddings.weight.data.uniform_(-initrange, initrange)\n",
    "#         self.c_embeddings.weight.data.uniform_(-0, 0)\n",
    "\n",
    "    def forward(self, pos_words, pos_conts, neg_conts):\n",
    "        \n",
    "        #Loss calculation, Levy&Goldberg word2vec Explained\n",
    "        #https://adoni.github.io/2017/11/08/word2vec-pytorch/\n",
    "        \n",
    "        w_out = self.w_embeddings(pos_words)\n",
    "        \n",
    "        pos_out = self.c_embeddings(pos_conts)\n",
    "        neg_out = self.c_embeddings(neg_conts)\n",
    "        \n",
    "#         print(neg_conts)\n",
    "#         print(pos_conts)\n",
    "#         print(pos_words)\n",
    "               \n",
    "        pos_val = torch.mul(w_out, pos_out).squeeze()\n",
    "        pos_val = torch.sum(pos_val, dim = 1)\n",
    "        pos_loss = F.logsigmoid(pos_val)\n",
    "        \n",
    "        neg_val = torch.bmm(neg_out, w_out.unsqueeze(2)).squeeze()\n",
    "        neg_val = torch.sum(neg_val, dim = 1)\n",
    "        neg_loss = F.logsigmoid(-neg_val)\n",
    "        \n",
    "        final_out = pos_loss + neg_loss.sum()\n",
    "        final_out = -final_out.sum()/len(pos_words) #neg and mean\n",
    "         \n",
    "        return final_out\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7061"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "no_batch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch, total loss, average loss, duration\n",
      "0 72023.55828857422 720.235582886 0:00:00.823988\n",
      "1 2799.283276319504 374.114207824 0:00:00.653378\n",
      "2 350.6550145149231 250.578321931 0:00:00.662555\n",
      "3 320.9006915092468 188.735993177 0:00:00.823187\n",
      "4 302.7348961830139 151.594264334 0:00:01.327941\n",
      "5 285.3464984893799 126.804131109 0:00:01.287951\n",
      "6 268.5066874027252 109.072836219 0:00:01.189773\n",
      "7 252.06097209453583 95.7538079064 0:00:01.135399\n",
      "8 235.88843822479248 85.3765941815 0:00:00.930522\n",
      "9 220.10784590244293 77.0590426092 0:00:01.054160\n"
     ]
    }
   ],
   "source": [
    "model = SkipGramNeg(vocab_size, embedding_dim)\n",
    "optimizer = optim.SparseAdam(model.parameters(), lr = learning_rate)\n",
    "\n",
    "losses = []\n",
    "avg_losses = []\n",
    "\n",
    "no_batch = 100\n",
    "print('epoch, total loss, average loss, duration')\n",
    "for e in range(epochs):\n",
    "    \n",
    "    then = datetime.now()\n",
    "    \n",
    "    total_loss = 0.0\n",
    "    for b in range(no_batch):\n",
    "        \n",
    "        words = word_batches[b]\n",
    "        contexts = context_batches[b]\n",
    "        neg_contexts = neg_context_batches[b]\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        loss = model(words, contexts, neg_contexts)\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()  \n",
    "    \n",
    "    now = datetime.now()\n",
    "        \n",
    "    losses.append(total_loss)\n",
    "    \n",
    "    avg_loss = np.mean(losses)/no_batch\n",
    "    \n",
    "    print(e, total_loss, avg_loss, now-then)\n",
    "    \n",
    "    avg_losses.append(avg_loss)\n",
    "    \n",
    "    wm, cm = get_embeddings(model)\n",
    "\n",
    "    save_embeddings(wm, 'wordvecs_skipgram_word_300' + label + '_'+str(e) + '.pickle')\n",
    "\n",
    "    save_embeddings(cm, 'wordvecs_skipgram_context_300' + label + '_'+str(e) +'.pickle')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_embeddings(model):\n",
    "    \n",
    "    return model.w_embeddings.weight.data, model.c_embeddings.weight.data\n",
    "\n",
    "def save_embeddings(embeds, file_name):\n",
    "    \n",
    "    with open(file_name, 'wb') as file:\n",
    "        pickle.dump(embeds.numpy(), file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngYhIlvv/Aae+88HqQYTVAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fb40b2c50f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "iteration= list(range(len(avg_losses)))\n",
    "\n",
    "plt.plot(iteration, avg_losses)\n",
    "plt.xlabel(\"Iterations for Skipgram\")\n",
    "plt.ylabel('Average loss')\n",
    "plt.title('Evolution of average loss as a function of the iteration')\n",
    "plt.savefig(\"Skipgram.png\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "612"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(avg_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
